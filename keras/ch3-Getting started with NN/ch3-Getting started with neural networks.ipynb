{
  "cells": [
    {
      "cell_type": "markdown",
      "source": "# 神經網路入門\n本章，我們會將上一章節所學的知識應用於三個新問題，此問題涵蓋最常見的三個使用場景：(1).二分類問題、(2).多分類問題、(3).標量回歸問題。",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 3.1 神經網路剖析\n前面幾張介紹過，訓練神經網路主要圍繞以下四個面向：\n* 「層」、多少層組合成網路( 或模型 )。\n* 「輸入數據」、相對應的「目標」。\n* 「損失函數」，即用於學習的反饋訊號。\n* 「優化器」，決定學習過程如何進行。\u003cbr\u003e\u003cbr\u003e\n\n我們可以將四者關係可視化，如圖3.1所示，我們可以藉由多個層鏈接在一起，組成網路，將輸入數據映射為預測值。然後損失函數將這些預測值與相對應的目標進行比較後，得到損失值，其可用於衡量網路預測值與預期結果的匹配程度。再用優化器使用這個損失值來更新網路的權重。\u003cbr\u003e\n![3.1，網路、層、損失函數、優化器](../img/3.1.PNG)\u003cbr\u003e\n接下來，我們來進一步研究層、網路、損失函數、優化器之間的關係。\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 3.1.1 層：深度學習的基礎組件\n層是一個數據處理模塊，將輸入張量轉換為輸出張量。我們可以將層想成DL的樂高積木，Keras等框架則將這種比喻具體化，建構DL模型就是將「相互兼容」的多個層拼接在一起，以建立有用的數據變換流程。這裡，「層兼容性( layer compatibility )」具體指得是每一層只接受特定形狀的輸入張量，並返回特定形狀的輸出張量。舉例如下。\n",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "outputs": [],
      "source": "\u0027\u0027\u0027\n我們要創立一個層，只接受輸入維度大小為784的2D張量，\n這個層將返回一個維度大小為32的張量。\n\u0027\u0027\u0027\nfrom keras import layers\n\nlayers \u003d layers.Dense(32, input_shape\u003d(784, ))      # 有32個輸出位元的全連接層\n\n###\n# 因此，這個層後面只能接受32維度向量作為輸入的層。\n# 但別擔心，keras會自動匹配輸入層的形狀，如下：\n###\n\nfrom keras import models\nfrom keras import layers\n\nmodels \u003d models.Sequential()\nmodels.add(layers.Dense(32, input_shape\u003d(784, )))\nmodels.add(layers.Dense(32))\n\n###\n# 其中，第二層沒有指定輸入數據形狀的參數( input_shape )，\n# 相反，Keras可以自動推導出輸入形狀等於上一層的輸出形狀!!!\n###\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 3.1.2 模型：層構成的網路\nDL模型是由層構成的有向無環圖，亦即任意頂點出發無法經過若干條邊回到該點。最常見的例子就是層的線性堆疊，將單一輸入映射為單一輸出。\u003cbr\u003e\n當然，還有更多類型的網路結構，舉一些常見的網路拓樸結構如下：\u003cbr\u003e\n* 雙分支(　two-branch )網路\n* 多頭( multihead )網路\n* Inception 模塊 \u003cbr\u003e\u003cbr\u003e\n\n「網路拓樸」結構定義了一個假設空間( hypothesis space )又稱為可能性空間。回想一下第1章節ML的定義：\"在預先定義好的可能性問題中，利用反饋訊號來尋找輸入數據的有用表示。\"\u003cbr\u003e\u003cbr\u003e\n\n一旦選定了網路拓樸結構，意味著將可能性空間(假設空間)限定為一系列特定的張量運算，將輸入數據映射為輸出數據。然後，我們還需要對這些張量運算的權重張量找到一組合適的值。\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "### 3.1.3 損失函數與優化器：配置學習過程的關鍵\n一旦確定了網路架構，我們還需要選擇以下兩個參數。\n* 損失函數( 目標函數 )：在訓練過程中需要將其最小化，他能夠衡量當前任務是否已成功完成。\n* 優化器：決定如何基於損失函數對網路進行更新。\u003cbr\u003e\u003cbr\u003e\n\n開始實現keras前，我們考慮幾個重要的課題：\n* 當NN具有多個損失函數時：需所有Loss_function取平均，變成單一指標值。\n* 如何選正確的目標函數：想想我們建立一個愚蠢又無所不不能的AI，讓全體人類的平均幸福感最大化會發生甚麼事情?\n* 所面對的研究問題是甚麼：(1).二分類問題、(2).多分類問題、(3).標量回歸問題。每個問題可對應不同的損失函數，如，(1).-\u003e二元交叉熵損失函數、(2).分類交叉熵損失函數、(3).回歸問題 -\u003e MSE損失函數 、 序列問題 -\u003e 連結主義時序分類(CTC)損失函數。\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "## 3.2 Keras 簡介\n我們已經見過一個Keras模型的示例，就是MNIST的例子。典型的Keras工作流程就和那個例子類似。\n* (1).定義訓練數據：輸入張量和目標張量。\n* (2).定義層組成的網路( 或模型 )，將輸入映射到目標。\n* (3).配置學習過程：選擇損失函數、優化器和需要監控的指標。\n* (4).調用模型的fit方法在訓練數據上進行迭代。\u003cbr\u003e\n定義模型有兩種方法：一種是利用Sequential類，另一種是函數式API( functional API ，用於層組成的有無循環圖，讓我們可以構建任意形式的架構)。我們將兩者實現如下：\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "outputs": [],
      "source": "###\n# 首先是利用Sequential類定義的兩層模型\n# (注意，我們向第一層傳入了輸入數據的預期形狀)\n###\nfrom keras import models\nfrom keras import layers\n\nmodel \u003d models.Sequential()\nmodel.add(layers.Dense(32, activation\u003d\u0027relu\u0027, input_shape\u003d(784,)))\nmodel.add(layers.Dense(10, activation\u003d\u0027softmax\u0027))\n\n###\n# 下面使用函數式API定義的相同模型\n# 利用函數式API，我們可以操縱模型的數據張量\n# 並且將層應用於這個張量\n# 就好像這些層式函數一樣\n###\n\ninput_tensor \u003d layers.Input(shape\u003d(784,)) \nx \u003d layers.Dense(32, activation\u003d\u0027relu\u0027)(input_tensor)\noutput_tensor \u003d layers.Dense(10, activation\u003d\u0027softmax\u0027)(x)\n\nmodel \u003d models.Model(inputs\u003dinput_tensor, outputs\u003doutput_tensor)\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%%\n",
          "is_executing": false
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "一旦定義好了模型架構，接下來配置學習過程是在「編譯」這一步，我們需要指定模型使用的(1).優化器、(2).損失函數以及(3).學習過程所關心的「監控指標」，如下：\u003cbr\u003e\u003cbr\u003e\n\nfrom keras import optimizers    \u003cbr\u003e\u003cbr\u003e\n\nmodel.compile(optimizer\u003doptimizers.RMSprop(lr\u003d0.001), \u003cbr\u003e\n              loss\u003d\u0027mse\u0027,                      \n              metrics\u003d[\u0027accuracy\u0027]) \u003cbr\u003e\u003cbr\u003e\n              \n最後，學習過程就是通過fit () 方法將輸入數據的Numpy模組( 和對應的目標數據 )傳入模型，如下：\u003cbr\u003e\n\nmodel.fit(input_tensor, target_tensor, batch_size\u003d128, epochs\u003d10)\u003cbr\u003e\n",
      "metadata": {
        "pycharm": {
          "metadata": false,
          "name": "#%% md\n"
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": "# 本章小結\n* 本章，我們學習了：二分類問題、多分類問題以及標量回歸問題。\n* 在輸入數據之前，我們應該先對原始輸入數據進行預處理。\n* 如果數據特徵具有不同的取值範圍，那麼需對數據進行特徵縮放。\n* 隨著訓練進行，NN最終會過擬合，並在前所未見的數據上得到很差的結果。\n* 如果訓練數據不是很多，應該使用小型的網路結構，以避免過擬合問題發生。\n* 如果數據被分為多個類別，那麼中間層過小可能會導致訊息瓶頸。\n* 回歸問題使用的損失函數與評估指標都與分類問題不同。\n* 如果要處理的數據很少，K折驗證有助於評估模型。",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  ],
  "metadata": {
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "stem_cell": {
      "cell_type": "raw",
      "source": "",
      "metadata": {
        "pycharm": {
          "metadata": false
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}