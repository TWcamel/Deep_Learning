{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "###  define layer function  ###\n",
    "\n",
    "#此功能應包含3層layer，其中一層為隱藏層(看筆記page1)\n",
    "def add_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size])) #生成一隨機矩陣，為in_size列,out_size行\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1 ) #在tensorflow中，biases初始值不推薦為0，故使用0.1\n",
    "    Wx_plus_biases = tf.matmul(inputs, Weights) + biases\n",
    "    \n",
    "    ## 開始繳活函數 ##\n",
    "    if activation_function is None: #activaiton_function為0時\n",
    "        outputs = Wx_plus_biases\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_biases)\n",
    "    return outputs\n",
    "\n",
    "###  end of layer funciton  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>13.507114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.870369</td>\n",
       "      <td>6.132116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.496941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2.750000</td>\n",
       "      <td>8.053924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.500000</td>\n",
       "      <td>12.759242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>4.250000</td>\n",
       "      <td>18.566767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>25.534533</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                0           0\n",
       "count  300.000000  300.000000\n",
       "mean     3.500000   13.507114\n",
       "std      0.870369    6.132116\n",
       "min      2.000000    4.496941\n",
       "25%      2.750000    8.053924\n",
       "50%      3.500000   12.759242\n",
       "75%      4.250000   18.566767\n",
       "max      5.000000   25.534533"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###   build a neural network  ###\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "x_data = np.linspace(2, 5, 300)[:, np.newaxis]  #x_data有300比資料[5,9]的等差級數，一個feature，#Popolation\n",
    "noise = np.random.normal(0, 0.05, x_data.shape) #增加噪點( 常態(平均=0,標準差=0.05) )，防止預測曲線發現過擬和現象\n",
    "y_data = np.square(x_data) + 0.5 + noise #Profit\n",
    "\n",
    "\n",
    "xs= tf.placeholder(tf.float32, [None, 1])  #假設無論給多少example都Ok(None),輸出的feature只有1，此步驟為指定矩陣大小\n",
    "ys= tf.placeholder(tf.float32, [None, 1])\n",
    "\n",
    "l1 = add_layer(xs, 1, 10, activation_function = tf.nn.relu) #輸入層\n",
    "prediction = add_layer(l1, 10, 1, activation_function= None) #線性函數，因為假設無activation_function\n",
    "\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n",
    "                    reduction_indices=1)) #定義loss_function，並把reduction_indices=1，表示輸出為一個被壓扁的向量\n",
    "train_step = tf.train.GradientDescentOptimizer(.001).minimize(loss) #以學習率=0.1對於誤差(loss)進行優化\n",
    "\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "# 看下數據長怎樣 #\n",
    "df1 = pd.DataFrame(x_data)\n",
    "df2 = pd.DataFrame(y_data)\n",
    "dfs = pd.concat([df1,df2], axis=1)\n",
    "dfs.describe() \n",
    "# 看下數據長怎樣 #\n",
    "\n",
    "###  end of  building  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using matplotlib backend: Qt5Agg\n",
      "37.819942\n",
      "7.496574\n",
      "6.7131696\n",
      "5.995564\n",
      "5.336479\n",
      "4.7312474\n",
      "4.1769853\n",
      "3.6718895\n",
      "3.2146719\n",
      "2.8041387\n",
      "2.4388905\n",
      "2.1171367\n",
      "1.8366349\n",
      "1.5946641\n",
      "1.3881282\n",
      "1.2136586\n",
      "1.0677497\n",
      "0.9468885\n",
      "0.8476807\n",
      "0.7669312\n"
     ]
    }
   ],
   "source": [
    "###  visualization  ###\n",
    "%matplotlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(1,1,1) #1x1網格，第一個子格\n",
    "ax.scatter(x_data, y_data)\n",
    "plt.ion()\n",
    "plt.show()\n",
    "\n",
    "for i in range(1000) :\n",
    "    sess.run(train_step, feed_dict = {xs: x_data, ys: y_data}) #另一種對於GradientDescent的方法，小步驟訓練可提升下降效率\n",
    "    if i % 50 == 0 :  #每50步回報一次\n",
    "        print(sess.run(loss, feed_dict = {xs: x_data, ys: y_data}))   #每50步回報一次誤差函數\n",
    "             \n",
    "        ##  to see the step improvement  ##   \n",
    "        try:\n",
    "            ax.lines.remove(lines[0])\n",
    "        except Exception:\n",
    "            pass\n",
    "        prediction_value = sess.run(prediction, feed_dict={xs: x_data})\n",
    "        \n",
    "        # plot the prediction        \n",
    "        lines = ax.plot(x_data, prediction_value, 'r-', lw=5)\n",
    "        plt.pause(0.1)\n",
    "        \n",
    "        ##  end  ##\n",
    "plt.ioff()\n",
    "### end visualization  ###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
